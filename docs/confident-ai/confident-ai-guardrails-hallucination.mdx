---
id: confident-ai-guardrails-hallucination
title: Hallucination Guard
sidebar_label: Hallucination Guard
---

The **Hallucination Guard** is an output guard that analyzes the responses generated by your language model to detect any fabricated or inaccurate information, ensuring all outputs are factually correct and reliable.

:::info
`HallucinationGuard` is only available as an **output guard**.
:::

## Example

```python
from deepeval.guardrails import HallucinationGuard

model_output = "The capital of Australia is Sydney."

hallucination_guard = HallucinationGuard()
guard_result = hallucination_guard.guard(response=model_output)
```

There are no required arguments when initializing the `HallucinationGuard` object. The `guard` function accepts a single parameter `response`, which is the output of your LLM application.

## Interpreting Guard Result

```python
print(guard_result.score)
print(guard_result.score_breakdown)
```

`guard_result.score` is an integer that is `1` if the guard has been breached. The `score_breakdown` for `HallucinationGuard` is a dictionary containing:

- `score`: A binary value (1 or 0), where 1 indicates that hallucinated content was detected.
- `reason`: A brief explanation of why the score was assigned.

```json
{
  "score": 1,
  "reason": "The statement 'The capital of Australia is Sydney' is incorrect; the capital is Canberra."
}
```
